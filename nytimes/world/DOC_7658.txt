https://www.nytimes.com/2017/01/19/business/tesla-model-s-autopilot-fatal-crash.html
Tesla’s Self-Driving System Cleared in Deadly Crash - The New York Times
Driverless and Semiautonomous Vehicles,Tesla Motors Inc,Traffic Accidents and Safety,Automobile Safety Features and Defects,National Highway Traffic Safety Administration
Jan. 19, 2017
7658
Eight months after a fatal crash involving a Tesla Motors car operating in a computer-assisted mode, federal auto-safety regulators said their investigation of the car found no defects in the system that caused the accident and said Tesla’s Autopilot-enabled vehicles did not need to be recalled.The outcome is a major win for Tesla and its chief executive, Elon Musk, who has forcefully promoted the car’s technological prowess and ability to prevent accidents. The crash on May 7, 2016, attracted widespread attention and threatened to sidetrack the company’s push toward autonomous vehicles.The regulators warned, however, that advanced driver-assistance systems like the one in Tesla’s cars could be relied on to react properly in only some situations that arise on roadways. And the officials said that all automakers needed to be clear about how the systems should be used. Almost all major automakers are pursuing similar technology.“Not all systems can do all things,” said Bryan Thomas, a spokesman for the National Highway Traffic Safety Administration, the agency that investigated the car involved in the May accident. “There are driving scenarios that automatic emergency braking systems are not designed to address.”Tesla’s self-driving software, known as Autopilot, has proved adept at preventing Tesla cars from rear-ending other vehicles, but situations involving crossing traffic — as was the case in the crash that regulators investigated — “are beyond the performance capabilities of the system,” Mr. Thomas said.“Autopilot requires full driver engagement at all times,” he said.First introduced in October 2015, Autopilot uses radar and cameras to scan the road for obstacles and other vehicles, and can brake, accelerate and even pass other vehicles automatically. It tracks lines on highways to stay within lanes.The investigation was set off by the accident that killed Joshua Brown, a 40-year-old from Ohio. His 2015 Tesla Model S was operating under its Autopilot system on a state highway in Florida when it crashed into a tractor-trailer that was crossing the road in front of his car.Tesla has said its camera failed to recognize the white truck against a bright sky. But the agency essentially found that Mr. Brown was not paying attention to the road. It determined he set his car’s cruise control at 74 miles per hour about two minutes before the crash, and should have had at least seven seconds to notice the truck before crashing into it.Neither Autopilot nor Mr. Brown hit the brakes. The agency said that although Autopilot did not prevent the accident, the system performed as it was designed and intended, and therefore did not have a defect.A second federal agency, the National Transportation Safety Board, is also investigating the crash to determine its causes, but has not yet reached a conclusion.The highway agency’s inquiry, which focused only on whether there was a defect in the Autopilot system, looked at the Florida crash as well as “dozens,” as Mr. Thomas said, of other incidents involving Autopilot, including a Pennsylvania crash that left the driver and a passenger injured.The investigation was an early test of how regulators would handle automated driving systems. The agency could have ordered Tesla to issue a recall and disable Autopilot until any defect was fixed. The agency also has the power to fine automakers if they fail to take action promptly. Fines and mandated recalls are rare, however.In its final report, the agency said it “did not identify any defects in the design or performance” of Autopilot, or “any incidents in which the systems did not perform as designed.” The agency also noted that the frequency of crashes involving Tesla models declined by about 40 percent after the company introduced Autopilot.Telsa welcomed the findings.“We appreciate the thoroughness of N.H.T.S.A.’s report and its conclusion,” the company said in a statement.But in a point clearly aimed at Tesla, Mr. Thomas, the agency spokesman, cautioned automakers about naming and marketing semiautonomous driving systems in ways that give consumers the impression that they can let their cars drive themselves. “That’s an industrywide concern the agency has,” Mr. Thomas said.Tesla has faced calls from critics to rename Autopilot; they argue the current moniker suggests drivers can cede most tasks to the car’s computers and sensors. Last year, Mercedes-Benz pulled an ad for its driver-assistance system after complaints that it overstated the technology’s capabilities.“Carmakers have to be clear on what the driver’s responsibility is,” said Michelle Krebs, a senior analyst at Autotrader.com. “No car buyer should think there are fully automated vehicles on the market.”Tesla has the ability to wirelessly beam software updates to its cars, and it released a major update to Autopilot in September. The new version relies more on radar to identify other vehicles and potential obstacles, and to decide when to steer to avoid a problem or apply the brakes. Mr. Musk has said this might have prevented the May crash, although it runs counter to the widely held view that radar, while highly accurate in measuring distance, is less precise in determining the shape and size of objects.The new Autopilot software also gives drivers more frequent warnings to keep their hands on the steering wheel. After three warnings, Autopilot shuts off and cannot be restarted unless the driver stops and restarts the car.Under certain conditions, the older version of Autopilot could allow drivers to go several minutes without putting their hands on the steering wheel. Safety advocates complained that drivers could be lulled into a false sense of security.Mr. Brown posted videos on the internet showing himself riding in Autopilot mode. “The car’s doing it all itself,” he said in one, smiling as he took his hands from the wheel.While the update addressed some concerns that the agency had about Autopilot, Mr. Thomas said automakers could not rely on software updates to fix safety issues and avoid recalls.“If there is a defect identified, it’s not enough to do a software update,” Mr. Thomas said. “A recall still has to be issued.”Autopilot was the only system of its kind when it was introduced. But many other automakers are catching up. Mercedes’s advanced driver-assistance system, which is now available in the new 2017 E-Class sedan, is similar to Autopilot but requires drivers to have their hands on the wheel more frequently.General Motors and Audi are rolling out systems of their own later this year that have some capabilities that Autopilot lacks. Both of those companies use radar, cameras and lidar, a kind of radar based on lasers, to scan roadways. The G.M. and Audi systems will also monitor a driver’s eyes to determine if he or she is paying attention to the road.